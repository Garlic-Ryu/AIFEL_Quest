{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69bece08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] \n",
    "                                     for word in sentence.split()]\n",
    "\n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])\n",
    "\n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5e26ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aab5ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d923e01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.01551248  0.03800089 -0.04395893  0.02800931]\n",
      "  [ 0.03700484  0.04333696  0.03412478  0.03795974]\n",
      "  [-0.03795189  0.02338637 -0.03583932  0.00407376]\n",
      "  [ 0.02917546 -0.04867331  0.0188928   0.02722904]\n",
      "  [ 0.02840027 -0.00168171  0.02773613  0.00612907]]\n",
      "\n",
      " [[ 0.01551248  0.03800089 -0.04395893  0.02800931]\n",
      "  [ 0.03700484  0.04333696  0.03412478  0.03795974]\n",
      "  [-0.03170182 -0.04240062 -0.01120328  0.00701336]\n",
      "  [-0.03094193  0.01492741  0.04258921  0.04371445]\n",
      "  [ 0.02840027 -0.00168171  0.02773613  0.00612907]]\n",
      "\n",
      " [[ 0.01551248  0.03800089 -0.04395893  0.02800931]\n",
      "  [ 0.03886087 -0.02559493 -0.03294599 -0.02907532]\n",
      "  [ 0.03700484  0.04333696  0.03412478  0.03795974]\n",
      "  [-0.03795189  0.02338637 -0.03583932  0.00407376]\n",
      "  [ 0.0452452   0.02714148 -0.01520585 -0.00584054]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_to_index)\n",
    "word_vector_dim = 4\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype='object') \n",
    "\n",
    "raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                            value=word_to_index['<PAD>'],\n",
    "                                                            padding='post',\n",
    "                                                            maxlen=5)\n",
    "\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f04b0e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "357340f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0401c883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "imdb = tf.keras.datasets.imdb\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(f\"훈련 샘플 개수: {len(x_train)}, 테스트 개수: {len(x_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dc26234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "label 1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print('label', y_train[0])\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f82cc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[11])     \n",
    "print(word_to_index['the'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e827bdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(x_train[0], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d136e7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n",
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "word_to_index = {k:(v+3) for k, v in word_to_index.items()}\n",
    "\n",
    "\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])\n",
    "print(word_to_index['the']) \n",
    "print(index_to_word[4]) \n",
    "\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49563fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "\n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print(f'전체 문장의 {np.sum(num_tokens < max_tokens) / len(num_tokens)}%가 maxlen 설정값 이내에 포함됩니다. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d32b3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n",
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre', \n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre', \n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e56fe39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    \n",
    "word_vector_dim = 16  \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98e168c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c420b23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 3s 42ms/step - loss: 0.0777 - accuracy: 0.9822 - val_loss: 0.5003 - val_accuracy: 0.8463\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.0674 - accuracy: 0.9850 - val_loss: 0.5261 - val_accuracy: 0.8444\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1521 - accuracy: 0.9573 - val_loss: 0.5184 - val_accuracy: 0.8448\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.0832 - accuracy: 0.9785 - val_loss: 0.5118 - val_accuracy: 0.8415\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 0.0611 - accuracy: 0.9863 - val_loss: 0.5250 - val_accuracy: 0.8456\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.0556 - accuracy: 0.9886 - val_loss: 0.5359 - val_accuracy: 0.8445\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.0512 - accuracy: 0.9895 - val_loss: 0.5410 - val_accuracy: 0.8437\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.0507 - accuracy: 0.9897 - val_loss: 0.5442 - val_accuracy: 0.8439\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.0479 - accuracy: 0.9903 - val_loss: 0.5614 - val_accuracy: 0.8442\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.0441 - accuracy: 0.9912 - val_loss: 0.5762 - val_accuracy: 0.8437\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.0424 - accuracy: 0.9919 - val_loss: 0.5770 - val_accuracy: 0.8430\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.0409 - accuracy: 0.9919 - val_loss: 0.5828 - val_accuracy: 0.8429\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.0389 - accuracy: 0.9925 - val_loss: 0.5872 - val_accuracy: 0.8419\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.0364 - accuracy: 0.9931 - val_loss: 0.6008 - val_accuracy: 0.8432\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.0333 - accuracy: 0.9938 - val_loss: 0.6141 - val_accuracy: 0.8434\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.0314 - accuracy: 0.9941 - val_loss: 0.6256 - val_accuracy: 0.8425\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.0297 - accuracy: 0.9945 - val_loss: 0.6383 - val_accuracy: 0.8420\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.0334 - accuracy: 0.9931 - val_loss: 0.6368 - val_accuracy: 0.8386\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.0449 - accuracy: 0.9894 - val_loss: 0.6541 - val_accuracy: 0.8334\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.0403 - accuracy: 0.9909 - val_loss: 0.6949 - val_accuracy: 0.8355\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5391a97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 5s - loss: 0.7273 - accuracy: 0.8280\n",
      "[0.7273354530334473, 0.828000009059906]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b277bd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ff60f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6a11b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2256e2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_file_path = '/aiffel/aiffel/AIFEL_Quest/Exploration_04/sentiment_classification/data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3111435f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04076266,  0.02926965, -0.00213954, -0.04231619,  0.03868333,\n",
       "        0.03425995, -0.03845491,  0.02357891,  0.00503004,  0.05343014,\n",
       "        0.00064102,  0.06752136, -0.03583843,  0.04200235,  0.07172926,\n",
       "       -0.00852818], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "769d269c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stadium', 0.9084692001342773),\n",
       " ('ghetto', 0.9060187339782715),\n",
       " ('screwball', 0.9030367732048035),\n",
       " ('hold', 0.890879213809967),\n",
       " ('hints', 0.890342116355896),\n",
       " ('explosion', 0.8885762691497803),\n",
       " ('snippets', 0.8884989619255066),\n",
       " ('goodman', 0.8847399353981018),\n",
       " ('crucial', 0.884320855140686),\n",
       " ('mistaken', 0.8838977813720703)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b1f38308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec_path ='sentiment_classification/data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "79c1f462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loved', 0.6907791495323181),\n",
       " ('adore', 0.6816873550415039),\n",
       " ('loves', 0.661863386631012),\n",
       " ('passion', 0.6100708842277527),\n",
       " ('hate', 0.600395679473877),\n",
       " ('loving', 0.5886635780334473),\n",
       " ('affection', 0.5664337873458862),\n",
       " ('undying_love', 0.5547304749488831),\n",
       " ('absolutely_adore', 0.5536840558052063),\n",
       " ('adores', 0.5440906882286072)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff139e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8780d0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원 수 \n",
    "\n",
    "# 모델 구성\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "71a06b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 23s 88ms/step - loss: 0.6942 - accuracy: 0.5055 - val_loss: 0.6926 - val_accuracy: 0.5100\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 2s 69ms/step - loss: 0.6905 - accuracy: 0.5405 - val_loss: 0.6845 - val_accuracy: 0.5621\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 2s 70ms/step - loss: 0.6452 - accuracy: 0.6363 - val_loss: 0.5891 - val_accuracy: 0.7036\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 2s 70ms/step - loss: 0.4525 - accuracy: 0.8130 - val_loss: 0.3782 - val_accuracy: 0.8378\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 2s 70ms/step - loss: 0.2930 - accuracy: 0.8841 - val_loss: 0.3529 - val_accuracy: 0.8454\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 2s 70ms/step - loss: 0.2158 - accuracy: 0.9211 - val_loss: 0.3480 - val_accuracy: 0.8472\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 2s 70ms/step - loss: 0.1522 - accuracy: 0.9535 - val_loss: 0.3288 - val_accuracy: 0.8627\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.1090 - accuracy: 0.9713 - val_loss: 0.3438 - val_accuracy: 0.8628\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.0786 - accuracy: 0.9837 - val_loss: 0.3497 - val_accuracy: 0.8678\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.0552 - accuracy: 0.9921 - val_loss: 0.3797 - val_accuracy: 0.8616\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.0380 - accuracy: 0.9963 - val_loss: 0.3844 - val_accuracy: 0.8637\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.0259 - accuracy: 0.9981 - val_loss: 0.4088 - val_accuracy: 0.8627\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.0185 - accuracy: 0.9990 - val_loss: 0.4233 - val_accuracy: 0.8639\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.0136 - accuracy: 0.9994 - val_loss: 0.4392 - val_accuracy: 0.8628\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0102 - accuracy: 0.9994 - val_loss: 0.4554 - val_accuracy: 0.8618\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0076 - accuracy: 0.9998 - val_loss: 0.4699 - val_accuracy: 0.8641\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0061 - accuracy: 0.9998 - val_loss: 0.4852 - val_accuracy: 0.8617\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0051 - accuracy: 0.9998 - val_loss: 0.4972 - val_accuracy: 0.8625\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0043 - accuracy: 0.9997 - val_loss: 0.5062 - val_accuracy: 0.8619\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.5188 - val_accuracy: 0.8629\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa05056a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 2s - loss: 0.5675 - accuracy: 0.8468\n",
      "[0.5675192475318909, 0.8468400239944458]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
